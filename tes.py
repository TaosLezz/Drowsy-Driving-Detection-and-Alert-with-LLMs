"""Chá»‰ xá»­ lÃ½ ko hiá»ƒn thá»‹ video"""
# import cv2
# import torch
# import time
# import numpy as np
# from transformers import CLIPProcessor, CLIPModel
# from PIL import Image
# import collections

# # Cáº¥u hÃ¬nh thiáº¿t bá»‹
# device = "cuda" if torch.cuda.is_available() else "cpu"

# # Load model vÃ  processor má»™t láº§n
# model_path = r"E:\aHieu_LLMs\Drowsy-Driving-Detection-LLM\clip-vit-large-patch14"
# model = CLIPModel.from_pretrained(model_path, local_files_only=True).to(device)
# processor = CLIPProcessor.from_pretrained(model_path, local_files_only=True)

# # CÃ¢u mÃ´ táº£ tráº¡ng thÃ¡i
# texts = [
#     "A driver with open eyes and an alert expression",  # Tá»‰nh tÃ¡o
#     "A drowsy or sleeping driver with closed or half-closed eyes"  # Buá»“n ngá»§ / Ngá»§
# ]
# labels = ["Awake", "Drowsy or Sleeping"]

# # HÃ m dá»± Ä‘oÃ¡n tráº¡ng thÃ¡i tá»« frame áº£nh
# def predict(image):
#     inputs = processor(text=texts, images=image, return_tensors="pt", padding=True).to(device)
#     outputs = model(**inputs)
#     probs = outputs.logits_per_image.softmax(dim=1)
#     return labels[probs.argmax().item()], probs

# # Äá»c video
# video_path = r"E:\aHieu_LLMs\Drowsy-Driving-Detection-LLM\video\test.mp4"  
# cap = cv2.VideoCapture(video_path)
# fps = int(cap.get(cv2.CAP_PROP_FPS))  
# frame_interval = fps // 2 

# consecutive_drowsy = 0  
# alert_threshold = 3 
# frame_counter = 0

# while cap.isOpened():
#     ret, frame = cap.read()
#     if not ret:
#         break

#     if frame_counter % frame_interval == 0:
#         image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
#         start_time = time.time()
#         prediction, probs = predict(image)
#         end_time = time.time()
        
#         print(f"Frame {frame_counter}: {prediction} | Time: {end_time - start_time:.4f} s")

#         if prediction == "Drowsy or Sleeping":
#             consecutive_drowsy += 1
#         else:
#             consecutive_drowsy = 0
        
#         if consecutive_drowsy >= alert_threshold:
#             print("ðŸš¨ Cáº¢NH BÃO: TÃ i xáº¿ Ä‘ang buá»“n ngá»§! ðŸš¨")
#             consecutive_drowsy = 0 

#     frame_counter += 1

# cap.release()
# cv2.destroyAllWindows()


import cv2
import torch
import time
from transformers import CLIPProcessor, CLIPModel
from PIL import Image

# Cáº¥u hÃ¬nh thiáº¿t bá»‹
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load model vÃ  processor má»™t láº§n
model_path = r"E:\aHieu_LLMs\Drowsy-Driving-Detection-LLM\clip-vit-large-patch14"
model = CLIPModel.from_pretrained(model_path, local_files_only=True).to(device)
processor = CLIPProcessor.from_pretrained(model_path, local_files_only=True)

# CÃ¢u mÃ´ táº£ tráº¡ng thÃ¡i
texts = [
    "A driver with open eyes and an alert expression",  # Tá»‰nh tÃ¡o
    "A drowsy or sleeping driver with closed or half-closed eyes"  # Buá»“n ngá»§ / Ngá»§
]
labels = ["Awake", "Drowsy or Sleeping"]

# HÃ m dá»± Ä‘oÃ¡n tráº¡ng thÃ¡i tá»« frame áº£nh
def predict(image):
    inputs = processor(text=texts, images=image, return_tensors="pt", padding=True).to(device)
    outputs = model(**inputs)
    probs = outputs.logits_per_image.softmax(dim=1)
    return labels[probs.argmax().item()], probs

# Äá»c video
video_path = r"E:\aHieu_LLMs\Drowsy-Driving-Detection-LLM\video\test.mp4"  # Thay báº±ng Ä‘Æ°á»ng dáº«n video cá»§a báº¡n
cap = cv2.VideoCapture(video_path)
fps = int(cap.get(cv2.CAP_PROP_FPS))  # Láº¥y FPS cá»§a video
frame_interval = fps // 2  # Láº¥y 2 frame má»—i giÃ¢y

frame_width = int(cap.get(3))  # Chiá»u rá»™ng video
frame_height = int(cap.get(4))  # Chiá»u cao video

# Ghi video káº¿t quáº£
output_path = "output_video.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  
out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

consecutive_drowsy = 0  # Sá»‘ láº§n liÃªn tiáº¿p buá»“n ngá»§
alert_threshold = 3  # NgÆ°á»¡ng cáº£nh bÃ¡o
frame_counter = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    if frame_counter % frame_interval == 0:
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        start_time = time.time()
        prediction, probs = predict(image)
        end_time = time.time()
        
        print(f"Frame {frame_counter}: {prediction} | Time: {end_time - start_time:.4f} s")

        if prediction == "Drowsy or Sleeping":
            consecutive_drowsy += 1
        else:
            consecutive_drowsy = 0 
        
        if consecutive_drowsy >= alert_threshold:
            cv2.putText(frame, "ALERT! Driver is Drowsy!", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 
                        1.5, (0, 0, 255), 3, cv2.LINE_AA)
            consecutive_drowsy = 0  
        else:
            cv2.putText(frame, f"State: {prediction}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 
                        1.5, (0, 255, 0), 3, cv2.LINE_AA)

    cv2.imshow("Drowsiness Detection", frame)
    out.write(frame) 

    frame_counter += 1

    # Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()
